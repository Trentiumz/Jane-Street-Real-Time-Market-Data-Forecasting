{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee13fd81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:20.134885Z",
     "iopub.status.busy": "2024-12-30T16:50:20.134384Z",
     "iopub.status.idle": "2024-12-30T16:50:35.183707Z",
     "shell.execute_reply": "2024-12-30T16:50:35.182507Z"
    },
    "papermill": {
     "duration": 15.06081,
     "end_time": "2024-12-30T16:50:35.186308",
     "exception": false,
     "start_time": "2024-12-30T16:50:20.125498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import polars as pl # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gc\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b53715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.201711Z",
     "iopub.status.busy": "2024-12-30T16:50:35.200912Z",
     "iopub.status.idle": "2024-12-30T16:50:35.207431Z",
     "shell.execute_reply": "2024-12-30T16:50:35.206369Z"
    },
    "papermill": {
     "duration": 0.016513,
     "end_time": "2024-12-30T16:50:35.209753",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.193240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(15234)\n",
    "random.seed(15234)\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "tf.random.set_seed(15234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d0c61",
   "metadata": {
    "papermill": {
     "duration": 0.00604,
     "end_time": "2024-12-30T16:50:35.223689",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.217649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5537e4cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.238184Z",
     "iopub.status.busy": "2024-12-30T16:50:35.237744Z",
     "iopub.status.idle": "2024-12-30T16:50:35.245408Z",
     "shell.execute_reply": "2024-12-30T16:50:35.244269Z"
    },
    "papermill": {
     "duration": 0.017763,
     "end_time": "2024-12-30T16:50:35.247914",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.230151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = Path(\"/kaggle/input/jane-street-real-time-market-data-forecasting/\")\n",
    "preprocess_path = Path('/kaggle/input/js-preprocessing/')\n",
    "train_path = preprocess_path / Path(\"train/\")\n",
    "train_read_paths = [train_path / Path(f\"partition_id={i}/part-0.parquet\") for i in [0, 1, 2, 3, 4, 5, 6, 7]]\n",
    "val_read_paths = [train_path / Path(f\"partition_id={i}/part-0.parquet\") for i in [8]]\n",
    "test_read_paths = [train_path / Path(f\"partition_id={i}/part-0.parquet\") for i in [9]]\n",
    "\n",
    "data_base_path = Path(\"/kaggle/input/js-preprocessing/\")\n",
    "feature_data_path = data_base_path / Path(\"feature_data.csv\")\n",
    "\n",
    "target = \"responder_6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37814e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.264668Z",
     "iopub.status.busy": "2024-12-30T16:50:35.264274Z",
     "iopub.status.idle": "2024-12-30T16:50:35.271593Z",
     "shell.execute_reply": "2024-12-30T16:50:35.270476Z"
    },
    "papermill": {
     "duration": 0.017437,
     "end_time": "2024-12-30T16:50:35.273797",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.256360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    input_format = {\n",
    "        \"date_id\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"time_id\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"symbol_id\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"weight\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"features\": tf.TensorSpec(shape=(None, 79), dtype=tf.float32),\n",
    "        \"responders\": tf.TensorSpec(shape=(None, 9), dtype=tf.float32),\n",
    "        \"lags\": tf.TensorSpec(shape=(None, 9), dtype=tf.float32),\n",
    "        \"target\": tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    }\n",
    "    train_batch_size = 32768\n",
    "    val_batch_size = 512\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9e9972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.288682Z",
     "iopub.status.busy": "2024-12-30T16:50:35.288230Z",
     "iopub.status.idle": "2024-12-30T16:50:35.455516Z",
     "shell.execute_reply": "2024-12-30T16:50:35.454333Z"
    },
    "papermill": {
     "duration": 0.178001,
     "end_time": "2024-12-30T16:50:35.458446",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.280445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_format = 'feature_\\d\\d'\n",
    "responder_format = 'responder_\\d'\n",
    "lag_format = 'responder_\\d_lag'\n",
    "\n",
    "def chunk_features(chunk):\n",
    "    return chunk[[i for i in chunk.columns if re.fullmatch(feature_format, i)]]\n",
    "def chunk_lags(chunk):\n",
    "    return chunk[[i for i in chunk.columns if re.fullmatch(lag_format, i)]]\n",
    "\n",
    "def from_files(paths):\n",
    "    def to_ret():\n",
    "        for filepath in paths:\n",
    "            chunk = pl.read_parquet(filepath)\n",
    "            yield {\n",
    "                \"date_id\": chunk[\"date_id\"],\n",
    "                \"time_id\": chunk[\"time_id\"],\n",
    "                \"symbol_id\": chunk[\"symbol_id\"],\n",
    "                \"weight\": chunk[\"weight\"],\n",
    "                \"features\": chunk_features(chunk),\n",
    "                \"responders\": chunk[[i for i in chunk.columns if re.fullmatch(responder_format, i)]],\n",
    "                \"lags\": chunk_lags(chunk),\n",
    "                \"target\": chunk[target]\n",
    "            }\n",
    "    return to_ret\n",
    "\n",
    "train_raw = tf.data.Dataset.from_generator(\n",
    "    from_files(train_read_paths),\n",
    "    output_signature=config.input_format\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_raw = tf.data.Dataset.from_generator(\n",
    "    from_files(val_read_paths),\n",
    "    output_signature=config.input_format\n",
    ").cache()\n",
    "\n",
    "test_raw = tf.data.Dataset.from_generator(\n",
    "    from_files(test_read_paths),\n",
    "    output_signature=config.input_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06222283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.474830Z",
     "iopub.status.busy": "2024-12-30T16:50:35.473776Z",
     "iopub.status.idle": "2024-12-30T16:50:35.481971Z",
     "shell.execute_reply": "2024-12-30T16:50:35.480731Z"
    },
    "papermill": {
     "duration": 0.019075,
     "end_time": "2024-12-30T16:50:35.484371",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.465296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_id': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'time_id': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'symbol_id': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'weight': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'features': TensorSpec(shape=(None, 79), dtype=tf.float32, name=None),\n",
       " 'responders': TensorSpec(shape=(None, 9), dtype=tf.float32, name=None),\n",
       " 'lags': TensorSpec(shape=(None, 9), dtype=tf.float32, name=None),\n",
       " 'target': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedea180",
   "metadata": {
    "papermill": {
     "duration": 0.006631,
     "end_time": "2024-12-30T16:50:35.497797",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.491166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Filter & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e224c850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.513011Z",
     "iopub.status.busy": "2024-12-30T16:50:35.512587Z",
     "iopub.status.idle": "2024-12-30T16:50:35.613230Z",
     "shell.execute_reply": "2024-12-30T16:50:35.612166Z"
    },
    "papermill": {
     "duration": 0.111127,
     "end_time": "2024-12-30T16:50:35.615895",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.504768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_data_df = pl.read_csv(feature_data_path)\n",
    "means = np.asarray(feature_data_df['mean']).astype('float32')\n",
    "stds = np.asarray(feature_data_df['std']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741a8436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.630716Z",
     "iopub.status.busy": "2024-12-30T16:50:35.630345Z",
     "iopub.status.idle": "2024-12-30T16:50:35.891168Z",
     "shell.execute_reply": "2024-12-30T16:50:35.890101Z"
    },
    "papermill": {
     "duration": 0.271169,
     "end_time": "2024-12-30T16:50:35.893562",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.622393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_features(features):\n",
    "    return tf.where(\n",
    "        tf.logical_or(tf.math.is_nan(features), tf.math.is_inf(features)), \n",
    "        means, \n",
    "        features)\n",
    "\n",
    "def normalize_features(features):\n",
    "    return (features - means) / tf.math.maximum(1.0, stds)\n",
    "\n",
    "def clean_lags(lags):\n",
    "    return tf.where(\n",
    "        tf.logical_or(tf.math.is_nan(lags), tf.math.is_inf(lags)), \n",
    "        0.0, \n",
    "        lags)\n",
    "\n",
    "def format_data(features, lags):\n",
    "    return {\n",
    "        'feature': normalize_features(clean_features(features)),\n",
    "        'lags': clean_lags(lags)\n",
    "    }\n",
    "\n",
    "train_ds = train_raw.map(lambda i: (\n",
    "                        format_data(i['features'], i['lags']),\n",
    "                        i['target']\n",
    "                        )).unbatch().shuffle(10000).batch(config.train_batch_size)\n",
    "val_ds = val_raw.map(lambda i: (\n",
    "    format_data(i['features'], i['lags']),\n",
    "    i['target']\n",
    ")).unbatch().batch(config.val_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40852af4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T04:06:27.478694Z",
     "iopub.status.busy": "2024-12-18T04:06:27.477500Z",
     "iopub.status.idle": "2024-12-18T04:06:27.485848Z",
     "shell.execute_reply": "2024-12-18T04:06:27.484622Z",
     "shell.execute_reply.started": "2024-12-18T04:06:27.478647Z"
    },
    "papermill": {
     "duration": 0.006471,
     "end_time": "2024-12-30T16:50:35.906970",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.900499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train a Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebfceec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:35.922434Z",
     "iopub.status.busy": "2024-12-30T16:50:35.922033Z",
     "iopub.status.idle": "2024-12-30T16:50:36.020101Z",
     "shell.execute_reply": "2024-12-30T16:50:36.018957Z"
    },
    "papermill": {
     "duration": 0.109118,
     "end_time": "2024-12-30T16:50:36.022996",
     "exception": false,
     "start_time": "2024-12-30T16:50:35.913878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_layer = keras.Input(shape=(79,), name='feature')\n",
    "lag_layer = keras.Input(shape=(9,), name='lags')\n",
    "inp = keras.layers.Concatenate()([feat_layer, lag_layer])\n",
    "x = layers.Dropout(rate=0.2)(inp)\n",
    "x = layers.Dense(units=128, activation=\"silu\", kernel_regularizer=\"l1l2\")(x)\n",
    "x = layers.Dropout(rate=0.1)(x)\n",
    "x = layers.Dense(units=64, activation=\"silu\", kernel_regularizer=\"l1l2\")(x)\n",
    "x = layers.Dropout(rate=0.2)(x)\n",
    "x = layers.Dense(units=32, activation=\"silu\", kernel_regularizer=\"l1l2\")(x)\n",
    "x = layers.Dense(units=16, activation=\"silu\")(x)\n",
    "x = layers.Dense(units=4, activation=\"silu\")(x)\n",
    "x = layers.Dense(units=1)(x)\n",
    "model = keras.Model(inputs=[feat_layer, lag_layer], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4041b059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:36.038664Z",
     "iopub.status.busy": "2024-12-30T16:50:36.038276Z",
     "iopub.status.idle": "2024-12-30T16:50:36.057923Z",
     "shell.execute_reply": "2024-12-30T16:50:36.056787Z"
    },
    "papermill": {
     "duration": 0.03041,
     "end_time": "2024-12-30T16:50:36.060437",
     "exception": false,
     "start_time": "2024-12-30T16:50:36.030027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def r2_loss(y_true, y_pred):\n",
    "    return tf.math.reduce_sum((y_true - y_pred) ** 2) / tf.math.reduce_sum(y_true ** 2)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[keras.metrics.MeanAbsoluteError(), keras.metrics.R2Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a14f2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:50:36.075961Z",
     "iopub.status.busy": "2024-12-30T16:50:36.075526Z",
     "iopub.status.idle": "2024-12-30T18:39:17.716301Z",
     "shell.execute_reply": "2024-12-30T18:39:17.712622Z"
    },
    "papermill": {
     "duration": 6522.934188,
     "end_time": "2024-12-30T18:39:19.001401",
     "exception": false,
     "start_time": "2024-12-30T16:50:36.067213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "   1059/Unknown \u001b[1m292s\u001b[0m 268ms/step - loss: 0.8446 - mean_absolute_error: 0.5997 - r2_score: -0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 315ms/step - loss: 0.8445 - mean_absolute_error: 0.5997 - r2_score: -0.0024 - val_loss: 0.7436 - val_mean_absolute_error: 0.5556 - val_r2_score: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 276ms/step - loss: 0.8346 - mean_absolute_error: 0.5961 - r2_score: 0.0103 - val_loss: 0.7426 - val_mean_absolute_error: 0.5552 - val_r2_score: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 291ms/step - loss: 0.8334 - mean_absolute_error: 0.5957 - r2_score: 0.0117 - val_loss: 0.7421 - val_mean_absolute_error: 0.5551 - val_r2_score: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 318ms/step - loss: 0.8328 - mean_absolute_error: 0.5956 - r2_score: 0.0124 - val_loss: 0.7421 - val_mean_absolute_error: 0.5550 - val_r2_score: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 300ms/step - loss: 0.8325 - mean_absolute_error: 0.5954 - r2_score: 0.0128 - val_loss: 0.7419 - val_mean_absolute_error: 0.5549 - val_r2_score: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 275ms/step - loss: 0.8321 - mean_absolute_error: 0.5954 - r2_score: 0.0133 - val_loss: 0.7421 - val_mean_absolute_error: 0.5549 - val_r2_score: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 299ms/step - loss: 0.8318 - mean_absolute_error: 0.5953 - r2_score: 0.0136 - val_loss: 0.7419 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 305ms/step - loss: 0.8317 - mean_absolute_error: 0.5953 - r2_score: 0.0138 - val_loss: 0.7421 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 294ms/step - loss: 0.8314 - mean_absolute_error: 0.5952 - r2_score: 0.0141 - val_loss: 0.7419 - val_mean_absolute_error: 0.5548 - val_r2_score: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 313ms/step - loss: 0.8312 - mean_absolute_error: 0.5952 - r2_score: 0.0144 - val_loss: 0.7420 - val_mean_absolute_error: 0.5548 - val_r2_score: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 303ms/step - loss: 0.8314 - mean_absolute_error: 0.5952 - r2_score: 0.0140 - val_loss: 0.7417 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 294ms/step - loss: 0.8310 - mean_absolute_error: 0.5951 - r2_score: 0.0145 - val_loss: 0.7417 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 320ms/step - loss: 0.8309 - mean_absolute_error: 0.5951 - r2_score: 0.0146 - val_loss: 0.7419 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0139 - learning_rate: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 276ms/step - loss: 0.8308 - mean_absolute_error: 0.5951 - r2_score: 0.0148 - val_loss: 0.7420 - val_mean_absolute_error: 0.5548 - val_r2_score: 0.0138 - learning_rate: 5.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 321ms/step - loss: 0.8310 - mean_absolute_error: 0.5951 - r2_score: 0.0145 - val_loss: 0.7420 - val_mean_absolute_error: 0.5546 - val_r2_score: 0.0137 - learning_rate: 2.5000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 291ms/step - loss: 0.8308 - mean_absolute_error: 0.5950 - r2_score: 0.0148 - val_loss: 0.7421 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0136 - learning_rate: 2.5000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 313ms/step - loss: 0.8307 - mean_absolute_error: 0.5950 - r2_score: 0.0149 - val_loss: 0.7422 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0135 - learning_rate: 2.5000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 312ms/step - loss: 0.8309 - mean_absolute_error: 0.5951 - r2_score: 0.0146 - val_loss: 0.7422 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0134 - learning_rate: 1.2500e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 314ms/step - loss: 0.8308 - mean_absolute_error: 0.5950 - r2_score: 0.0148 - val_loss: 0.7422 - val_mean_absolute_error: 0.5547 - val_r2_score: 0.0135 - learning_rate: 1.2500e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 316ms/step - loss: 0.8307 - mean_absolute_error: 0.5950 - r2_score: 0.0149 - val_loss: 0.7422 - val_mean_absolute_error: 0.5546 - val_r2_score: 0.0135 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('/kaggle/working/fitted.keras', save_best_only=True),\n",
    "    keras.callbacks.ModelCheckpoint('/kaggle/working/intermediate.keras', save_best_only=False),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_delta=5e-5),\n",
    "    keras.callbacks.EarlyStopping(patience=8)\n",
    "]\n",
    "\n",
    "history = model.fit(x=train_ds, validation_data=val_ds, epochs=1000, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f52fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T21:16:33.404263Z",
     "iopub.status.busy": "2024-12-19T21:16:33.403835Z",
     "iopub.status.idle": "2024-12-19T21:16:41.038672Z",
     "shell.execute_reply": "2024-12-19T21:16:41.037480Z",
     "shell.execute_reply.started": "2024-12-19T21:16:33.404225Z"
    },
    "papermill": {
     "duration": 1.284826,
     "end_time": "2024-12-30T18:39:21.599528",
     "exception": false,
     "start_time": "2024-12-30T18:39:20.314702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d66e4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:39:24.233019Z",
     "iopub.status.busy": "2024-12-30T18:39:24.232429Z",
     "iopub.status.idle": "2024-12-30T18:39:24.410817Z",
     "shell.execute_reply": "2024-12-30T18:39:24.409950Z"
    },
    "papermill": {
     "duration": 1.522132,
     "end_time": "2024-12-30T18:39:24.413070",
     "exception": false,
     "start_time": "2024-12-30T18:39:22.890938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = test_raw.map(lambda i: (\n",
    "                        format_data(i['features'], i['lags']),\n",
    "                        i['target']\n",
    "                        )).unbatch().batch(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f0ac7f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:39:26.926023Z",
     "iopub.status.busy": "2024-12-30T18:39:26.925547Z",
     "iopub.status.idle": "2024-12-30T18:39:27.124188Z",
     "shell.execute_reply": "2024-12-30T18:39:27.123191Z"
    },
    "papermill": {
     "duration": 1.425766,
     "end_time": "2024-12-30T18:39:27.126586",
     "exception": false,
     "start_time": "2024-12-30T18:39:25.700820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/kaggle/working/fitted.keras', custom_objects={\n",
    "    'r2_loss': r2_loss\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3291c7ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:39:29.698785Z",
     "iopub.status.busy": "2024-12-30T18:39:29.698390Z",
     "iopub.status.idle": "2024-12-30T18:40:21.894607Z",
     "shell.execute_reply": "2024-12-30T18:40:21.893540Z"
    },
    "papermill": {
     "duration": 53.487511,
     "end_time": "2024-12-30T18:40:21.896801",
     "exception": false,
     "start_time": "2024-12-30T18:39:28.409290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3ms/step - loss: 0.6666 - mean_absolute_error: 0.5288 - r2_score: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6577768325805664, 0.5324712991714478, 0.007621109485626221]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c725ff",
   "metadata": {
    "papermill": {
     "duration": 1.373351,
     "end_time": "2024-12-30T18:40:24.640395",
     "exception": false,
     "start_time": "2024-12-30T18:40:23.267044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Online Retrain Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f867b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:27.313305Z",
     "iopub.status.busy": "2024-12-30T18:40:27.312885Z",
     "iopub.status.idle": "2024-12-30T18:40:27.502677Z",
     "shell.execute_reply": "2024-12-30T18:40:27.501692Z"
    },
    "papermill": {
     "duration": 1.52333,
     "end_time": "2024-12-30T18:40:27.505229",
     "exception": false,
     "start_time": "2024-12-30T18:40:25.981899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "old_model = keras.models.load_model('/kaggle/working/fitted.keras', custom_objects={\n",
    "    'r2_loss': r2_loss\n",
    "})\n",
    "new_model = keras.models.load_model('/kaggle/working/fitted.keras', custom_objects={\n",
    "    'r2_loss': r2_loss\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335dd172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:30.184518Z",
     "iopub.status.busy": "2024-12-30T18:40:30.184102Z",
     "iopub.status.idle": "2024-12-30T18:40:32.328171Z",
     "shell.execute_reply": "2024-12-30T18:40:32.327247Z"
    },
    "papermill": {
     "duration": 3.486047,
     "end_time": "2024-12-30T18:40:32.330460",
     "exception": false,
     "start_time": "2024-12-30T18:40:28.844413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_format = \"(date_id)|(time_id)|(symbol_id)|(weight)|(feature_\\d\\d)|(responder_\\d)\"\n",
    "test_df = pl.concat([pl.read_parquet(i) for i in test_read_paths])\n",
    "test_df = test_df[[i for i in test_df.columns if re.fullmatch(original_format, i)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ceb14b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:35.051347Z",
     "iopub.status.busy": "2024-12-30T18:40:35.050970Z",
     "iopub.status.idle": "2024-12-30T18:40:35.064049Z",
     "shell.execute_reply": "2024-12-30T18:40:35.062928Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.345871,
     "end_time": "2024-12-30T18:40:35.065924",
     "exception": false,
     "start_time": "2024-12-30T18:40:33.720053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = ['feature_00',\n",
    " 'feature_01',\n",
    " 'feature_02',\n",
    " 'feature_03',\n",
    " 'feature_04',\n",
    " 'feature_05',\n",
    " 'feature_06',\n",
    " 'feature_07',\n",
    " 'feature_08',\n",
    " 'feature_09',\n",
    " 'feature_10',\n",
    " 'feature_11',\n",
    " 'feature_12',\n",
    " 'feature_13',\n",
    " 'feature_14',\n",
    " 'feature_15',\n",
    " 'feature_16',\n",
    " 'feature_17',\n",
    " 'feature_18',\n",
    " 'feature_19',\n",
    " 'feature_20',\n",
    " 'feature_21',\n",
    " 'feature_22',\n",
    " 'feature_23',\n",
    " 'feature_24',\n",
    " 'feature_25',\n",
    " 'feature_26',\n",
    " 'feature_27',\n",
    " 'feature_28',\n",
    " 'feature_29',\n",
    " 'feature_30',\n",
    " 'feature_31',\n",
    " 'feature_32',\n",
    " 'feature_33',\n",
    " 'feature_34',\n",
    " 'feature_35',\n",
    " 'feature_36',\n",
    " 'feature_37',\n",
    " 'feature_38',\n",
    " 'feature_39',\n",
    " 'feature_40',\n",
    " 'feature_41',\n",
    " 'feature_42',\n",
    " 'feature_43',\n",
    " 'feature_44',\n",
    " 'feature_45',\n",
    " 'feature_46',\n",
    " 'feature_47',\n",
    " 'feature_48',\n",
    " 'feature_49',\n",
    " 'feature_50',\n",
    " 'feature_51',\n",
    " 'feature_52',\n",
    " 'feature_53',\n",
    " 'feature_54',\n",
    " 'feature_55',\n",
    " 'feature_56',\n",
    " 'feature_57',\n",
    " 'feature_58',\n",
    " 'feature_59',\n",
    " 'feature_60',\n",
    " 'feature_61',\n",
    " 'feature_62',\n",
    " 'feature_63',\n",
    " 'feature_64',\n",
    " 'feature_65',\n",
    " 'feature_66',\n",
    " 'feature_67',\n",
    " 'feature_68',\n",
    " 'feature_69',\n",
    " 'feature_70',\n",
    " 'feature_71',\n",
    " 'feature_72',\n",
    " 'feature_73',\n",
    " 'feature_74',\n",
    " 'feature_75',\n",
    " 'feature_76',\n",
    " 'feature_77',\n",
    " 'feature_78',\n",
    " 'responder_0_lag',\n",
    " 'responder_1_lag',\n",
    " 'responder_2_lag',\n",
    " 'responder_3_lag',\n",
    " 'responder_4_lag',\n",
    " 'responder_5_lag',\n",
    " 'responder_6_lag',\n",
    " 'responder_7_lag',\n",
    " 'responder_8_lag']\n",
    "responder_names = ['responder_0',\n",
    " 'responder_1',\n",
    " 'responder_2',\n",
    " 'responder_3',\n",
    " 'responder_4',\n",
    " 'responder_5',\n",
    " 'responder_6',\n",
    " 'responder_7',\n",
    " 'responder_8']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d6c651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:37.725516Z",
     "iopub.status.busy": "2024-12-30T18:40:37.724167Z",
     "iopub.status.idle": "2024-12-30T18:40:37.731847Z",
     "shell.execute_reply": "2024-12-30T18:40:37.730666Z"
    },
    "papermill": {
     "duration": 1.340388,
     "end_time": "2024-12-30T18:40:37.733846",
     "exception": false,
     "start_time": "2024-12-30T18:40:36.393458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_online_model(past_df, num_iterations = 10):\n",
    "    print(\"training new model\")\n",
    "    model = keras.models.load_model('/kaggle/working/fitted.keras', custom_objects={\n",
    "        'r2_loss': r2_loss\n",
    "    })\n",
    "    model.optimizer.learning_rate.assign(5e-5)\n",
    "\n",
    "    x_train = format_data(chunk_features(past_df), chunk_lags(past_df))\n",
    "    y_train = past_df[target]\n",
    "    model.fit(x=x_train, y=y_train, batch_size=past_df.shape[0], epochs=num_iterations)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7d42528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:40.493074Z",
     "iopub.status.busy": "2024-12-30T18:40:40.492601Z",
     "iopub.status.idle": "2024-12-30T18:40:40.507096Z",
     "shell.execute_reply": "2024-12-30T18:40:40.505820Z"
    },
    "papermill": {
     "duration": 1.437439,
     "end_time": "2024-12-30T18:40:40.509570",
     "exception": false,
     "start_time": "2024-12-30T18:40:39.072131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "past_data_cols = feature_names + ['date_id', 'time_id', 'symbol_id']\n",
    "past_responder_cols = responder_names + ['date_id', 'time_id', 'symbol_id']\n",
    "past_df_cols = feature_names + responder_names + ['date_id', 'time_id', 'symbol_id']\n",
    "\n",
    "class PastStorage:\n",
    "    def __init__(self):\n",
    "        self.past_df = None\n",
    "        self.last_day_data = None\n",
    "        self.last_day_id = None\n",
    "    def reformat_lags(lags: pl.DataFrame):\n",
    "        last_day_ans = lags\n",
    "        for i in range(9):\n",
    "            for j in [col for col in last_day_ans.columns if re.search(f'responder_{i}', col)]:\n",
    "                last_day_ans = last_day_ans.rename({j: f\"responder_{i}\"})\n",
    "        return last_day_ans\n",
    "    def append_to(df: pl.DataFrame | None, chunk: pl.DataFrame):\n",
    "        if df is None:\n",
    "            return chunk\n",
    "        else:\n",
    "            return pl.concat([df, chunk])\n",
    "        \n",
    "    def data_inc(self, test_full: pl.DataFrame, lags: pl.DataFrame | None):\n",
    "        global past_data_cols, past_responder_cols\n",
    "        if self.last_day_id is None:\n",
    "            self.last_day_id = test_full['date_id'][0]\n",
    "        \n",
    "        # use the data from the previous day for today's information\n",
    "        if lags is not None:\n",
    "            assert self.last_day_id != test_full['date_id'][0]\n",
    "\n",
    "            self.last_day_ans = PastStorage.reformat_lags(lags)\n",
    "            to_append = self.last_day_data.join(self.last_day_ans, ['date_id', 'time_id', 'symbol_id'], how='left')\n",
    "\n",
    "            self.past_df = PastStorage.append_to(self.past_df, to_append[past_df_cols])\n",
    "            print(\"Check for past dataframe cleanness:\", self.past_df.shape, self.past_df['responder_0'].is_null().sum())\n",
    "\n",
    "            self.last_day_data = None\n",
    "            self.last_day_id = test_full['date_id'][0]\n",
    "\n",
    "        # append the data to the previous day... should always be the same as last_day_id\n",
    "        assert self.last_day_id == test_full['date_id'][0]\n",
    "        self.last_day_data = PastStorage.append_to(self.last_day_data, test_full[past_data_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daf06bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:43.211364Z",
     "iopub.status.busy": "2024-12-30T18:40:43.210986Z",
     "iopub.status.idle": "2024-12-30T18:40:43.224324Z",
     "shell.execute_reply": "2024-12-30T18:40:43.223115Z"
    },
    "papermill": {
     "duration": 1.369412,
     "end_time": "2024-12-30T18:40:43.226466",
     "exception": false,
     "start_time": "2024-12-30T18:40:41.857054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lags_ : pl.DataFrame | None = None\n",
    "storage = PastStorage()\n",
    "days_per_update = 5\n",
    "cur_day = 0\n",
    "\n",
    "# Replace this function with your inference code.\n",
    "# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n",
    "# Each batch of predictions (except the very first) must be returned within 1 minute of the batch features being provided.\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_, storage, old_model, new_model, cur_day, days_per_update\n",
    "    \n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "        \n",
    "    if lags_ is not None:\n",
    "        last_reading = lags_.group_by(('date_id', 'symbol_id'), maintain_order=True).last()\n",
    "        for i in range(9):\n",
    "            for j in [col for col in last_reading.columns if re.search(f'responder_{i}', col)]:\n",
    "                last_reading = last_reading.rename({j: f\"responder_{i}_lag\"})\n",
    "\n",
    "        selected_cols = ['date_id', 'symbol_id'] + [i for i in last_reading.columns if re.fullmatch(lag_format, i)]\n",
    "        join_to = last_reading.with_columns(last_reading['date_id'] + 1)[selected_cols]\n",
    "        test_grouped = test.join(join_to, ['date_id', 'symbol_id'], how='left')\n",
    "    else:\n",
    "        test_grouped = test\n",
    "        for i in range(9):\n",
    "            test_grouped = test_grouped.with_columns(pl.lit(None).cast(pl.Float32).alias(f\"responder_{i}_lag\"))\n",
    "    \n",
    "    input_features = format_data(chunk_features(test_grouped), chunk_lags(test_grouped))\n",
    "    old_y = np.asarray(old_model.predict(input_features, verbose=0)).reshape((-1,))\n",
    "    new_y = np.asarray(new_model.predict(input_features, verbose=0)).reshape((-1,))\n",
    "    output_y = (old_y + new_y) / 2\n",
    "    predictions = pl.DataFrame({\n",
    "        \"row_id\": test['row_id'],\n",
    "        \"responder_6\": output_y\n",
    "    })\n",
    "\n",
    "    storage.data_inc(test_grouped, lags)\n",
    "    if lags is not None:\n",
    "        cur_day += 1\n",
    "        if cur_day == days_per_update:\n",
    "            new_model = train_online_model(storage.past_df)\n",
    "            storage.past_df = None\n",
    "        cur_day %= days_per_update\n",
    "\n",
    "    if isinstance(predictions, pl.DataFrame):\n",
    "        assert predictions.columns == ['row_id', 'responder_6']\n",
    "    elif isinstance(predictions, pd.DataFrame):\n",
    "        assert (predictions.columns == ['row_id', 'responder_6']).all()\n",
    "    else:\n",
    "        raise TypeError('The predict function must return a DataFrame')\n",
    "    # Confirm has as many rows as the test data.\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b369556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:45.858594Z",
     "iopub.status.busy": "2024-12-30T18:40:45.858143Z",
     "iopub.status.idle": "2024-12-30T18:40:45.864155Z",
     "shell.execute_reply": "2024-12-30T18:40:45.862960Z"
    },
    "papermill": {
     "duration": 1.340737,
     "end_time": "2024-12-30T18:40:45.866454",
     "exception": false,
     "start_time": "2024-12-30T18:40:44.525717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "by_days = test_df.group_by(['date_id', 'time_id'], maintain_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c60afd6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:48.529087Z",
     "iopub.status.busy": "2024-12-30T18:40:48.528658Z",
     "iopub.status.idle": "2024-12-30T18:40:48.543883Z",
     "shell.execute_reply": "2024-12-30T18:40:48.542712Z"
    },
    "papermill": {
     "duration": 1.337054,
     "end_time": "2024-12-30T18:40:48.546027",
     "exception": false,
     "start_time": "2024-12-30T18:40:47.208973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_date = None\n",
    "last_lag = None\n",
    "\n",
    "predictions = pl.DataFrame(schema={'responder_6': pl.Float32})\n",
    "answers = pl.DataFrame(schema={'responder_6': pl.Float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7597d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T18:40:51.191298Z",
     "iopub.status.busy": "2024-12-30T18:40:51.190397Z",
     "iopub.status.idle": "2024-12-31T02:24:38.606552Z",
     "shell.execute_reply": "2024-12-31T02:24:38.605112Z"
    },
    "papermill": {
     "duration": 27828.74242,
     "end_time": "2024-12-31T02:24:38.610772",
     "exception": false,
     "start_time": "2024-12-30T18:40:49.868352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100\n",
      "Processing 200\n",
      "Processing 300\n",
      "Processing 400\n",
      "Processing 500\n",
      "Processing 600\n",
      "Processing 700\n",
      "Processing 800\n",
      "Processing 900\n",
      "Check for past dataframe cleanness: (35816, 100) 0\n",
      "Processing 1000\n",
      "Processing 1100\n",
      "Processing 1200\n",
      "Processing 1300\n",
      "Processing 1400\n",
      "Processing 1500\n",
      "Processing 1600\n",
      "Processing 1700\n",
      "Processing 1800\n",
      "Processing 1900\n",
      "Check for past dataframe cleanness: (73568, 100) 0\n",
      "Processing 2000\n",
      "Processing 2100\n",
      "Processing 2200\n",
      "Processing 2300\n",
      "Processing 2400\n",
      "Processing 2500\n",
      "Processing 2600\n",
      "Processing 2700\n",
      "Processing 2800\n",
      "Processing 2900\n",
      "Check for past dataframe cleanness: (109384, 100) 0\n",
      "Processing 3000\n",
      "Processing 3100\n",
      "Processing 3200\n",
      "Processing 3300\n",
      "Processing 3400\n",
      "Processing 3500\n",
      "Processing 3600\n",
      "Processing 3700\n",
      "Processing 3800\n",
      "Check for past dataframe cleanness: (147136, 100) 0\n",
      "Processing 3900\n",
      "Processing 4000\n",
      "Processing 4100\n",
      "Processing 4200\n",
      "Processing 4300\n",
      "Processing 4400\n",
      "Processing 4500\n",
      "Processing 4600\n",
      "Processing 4700\n",
      "Processing 4800\n",
      "Check for past dataframe cleanness: (184888, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4485 - mean_absolute_error: 0.4301 - r2_score: 0.0034\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4486 - mean_absolute_error: 0.4302 - r2_score: 0.0031\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4485 - mean_absolute_error: 0.4302 - r2_score: 0.0034\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4486 - mean_absolute_error: 0.4303 - r2_score: 0.0031\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4487 - mean_absolute_error: 0.4302 - r2_score: 0.0029\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4485 - mean_absolute_error: 0.4301 - r2_score: 0.0033\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4482 - mean_absolute_error: 0.4301 - r2_score: 0.0039\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4483 - mean_absolute_error: 0.4301 - r2_score: 0.0037\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4486 - mean_absolute_error: 0.4303 - r2_score: 0.0031\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4485 - mean_absolute_error: 0.4302 - r2_score: 0.0033\n",
      "Processing 4900\n",
      "Processing 5000\n",
      "Processing 5100\n",
      "Processing 5200\n",
      "Processing 5300\n",
      "Processing 5400\n",
      "Processing 5500\n",
      "Processing 5600\n",
      "Processing 5700\n",
      "Processing 5800\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 5900\n",
      "Processing 6000\n",
      "Processing 6100\n",
      "Processing 6200\n",
      "Processing 6300\n",
      "Processing 6400\n",
      "Processing 6500\n",
      "Processing 6600\n",
      "Processing 6700\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 6800\n",
      "Processing 6900\n",
      "Processing 7000\n",
      "Processing 7100\n",
      "Processing 7200\n",
      "Processing 7300\n",
      "Processing 7400\n",
      "Processing 7500\n",
      "Processing 7600\n",
      "Processing 7700\n",
      "Check for past dataframe cleanness: (113256, 100) 0\n",
      "Processing 7800\n",
      "Processing 7900\n",
      "Processing 8000\n",
      "Processing 8100\n",
      "Processing 8200\n",
      "Processing 8300\n",
      "Processing 8400\n",
      "Processing 8500\n",
      "Processing 8600\n",
      "Processing 8700\n",
      "Check for past dataframe cleanness: (151008, 100) 0\n",
      "Processing 8800\n",
      "Processing 8900\n",
      "Processing 9000\n",
      "Processing 9100\n",
      "Processing 9200\n",
      "Processing 9300\n",
      "Processing 9400\n",
      "Processing 9500\n",
      "Processing 9600\n",
      "Check for past dataframe cleanness: (188760, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.6185 - mean_absolute_error: 0.5356 - r2_score: -0.0029\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6185 - mean_absolute_error: 0.5354 - r2_score: -0.0029\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6184 - mean_absolute_error: 0.5355 - r2_score: -0.0028\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6185 - mean_absolute_error: 0.5356 - r2_score: -0.0030\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6182 - mean_absolute_error: 0.5354 - r2_score: -0.0025\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6175 - mean_absolute_error: 0.5351 - r2_score: -0.0012\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6175 - mean_absolute_error: 0.5351 - r2_score: -0.0013\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6174 - mean_absolute_error: 0.5349 - r2_score: -0.0012\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6174 - mean_absolute_error: 0.5349 - r2_score: -0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6170 - mean_absolute_error: 0.5348 - r2_score: -4.8018e-04\n",
      "Processing 9700\n",
      "Processing 9800\n",
      "Processing 9900\n",
      "Processing 10000\n",
      "Processing 10100\n",
      "Processing 10200\n",
      "Processing 10300\n",
      "Processing 10400\n",
      "Processing 10500\n",
      "Processing 10600\n",
      "Check for past dataframe cleanness: (35816, 100) 0\n",
      "Processing 10700\n",
      "Processing 10800\n",
      "Processing 10900\n",
      "Processing 11000\n",
      "Processing 11100\n",
      "Processing 11200\n",
      "Processing 11300\n",
      "Processing 11400\n",
      "Processing 11500\n",
      "Processing 11600\n",
      "Check for past dataframe cleanness: (73568, 100) 0\n",
      "Processing 11700\n",
      "Processing 11800\n",
      "Processing 11900\n",
      "Processing 12000\n",
      "Processing 12100\n",
      "Processing 12200\n",
      "Processing 12300\n",
      "Processing 12400\n",
      "Processing 12500\n",
      "Check for past dataframe cleanness: (103576, 100) 0\n",
      "Processing 12600\n",
      "Processing 12700\n",
      "Processing 12800\n",
      "Processing 12900\n",
      "Processing 13000\n",
      "Processing 13100\n",
      "Processing 13200\n",
      "Processing 13300\n",
      "Processing 13400\n",
      "Processing 13500\n",
      "Check for past dataframe cleanness: (141328, 100) 0\n",
      "Processing 13600\n",
      "Processing 13700\n",
      "Processing 13800\n",
      "Processing 13900\n",
      "Processing 14000\n",
      "Processing 14100\n",
      "Processing 14200\n",
      "Processing 14300\n",
      "Processing 14400\n",
      "Processing 14500\n",
      "Check for past dataframe cleanness: (179080, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.8160 - mean_absolute_error: 0.6121 - r2_score: 0.0102\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8162 - mean_absolute_error: 0.6122 - r2_score: 0.0099\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8158 - mean_absolute_error: 0.6120 - r2_score: 0.0105\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8168 - mean_absolute_error: 0.6123 - r2_score: 0.0092\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8158 - mean_absolute_error: 0.6120 - r2_score: 0.0104\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8159 - mean_absolute_error: 0.6118 - r2_score: 0.0103\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8160 - mean_absolute_error: 0.6119 - r2_score: 0.0102\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8161 - mean_absolute_error: 0.6120 - r2_score: 0.0101\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8161 - mean_absolute_error: 0.6120 - r2_score: 0.0101\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8160 - mean_absolute_error: 0.6119 - r2_score: 0.0102\n",
      "Processing 14600\n",
      "Processing 14700\n",
      "Processing 14800\n",
      "Processing 14900\n",
      "Processing 15000\n",
      "Processing 15100\n",
      "Processing 15200\n",
      "Processing 15300\n",
      "Processing 15400\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 15500\n",
      "Processing 15600\n",
      "Processing 15700\n",
      "Processing 15800\n",
      "Processing 15900\n",
      "Processing 16000\n",
      "Processing 16100\n",
      "Processing 16200\n",
      "Processing 16300\n",
      "Processing 16400\n",
      "Check for past dataframe cleanness: (74536, 100) 0\n",
      "Processing 16500\n",
      "Processing 16600\n",
      "Processing 16700\n",
      "Processing 16800\n",
      "Processing 16900\n",
      "Processing 17000\n",
      "Processing 17100\n",
      "Processing 17200\n",
      "Processing 17300\n",
      "Processing 17400\n",
      "Check for past dataframe cleanness: (112288, 100) 0\n",
      "Processing 17500\n",
      "Processing 17600\n",
      "Processing 17700\n",
      "Processing 17800\n",
      "Processing 17900\n",
      "Processing 18000\n",
      "Processing 18100\n",
      "Processing 18200\n",
      "Processing 18300\n",
      "Check for past dataframe cleanness: (150040, 100) 0\n",
      "Processing 18400\n",
      "Processing 18500\n",
      "Processing 18600\n",
      "Processing 18700\n",
      "Processing 18800\n",
      "Processing 18900\n",
      "Processing 19000\n",
      "Processing 19100\n",
      "Processing 19200\n",
      "Processing 19300\n",
      "Check for past dataframe cleanness: (186824, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4986 - mean_absolute_error: 0.4689 - r2_score: 2.2662e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4986 - mean_absolute_error: 0.4689 - r2_score: 3.1185e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4989 - mean_absolute_error: 0.4689 - r2_score: -3.2175e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4985 - mean_absolute_error: 0.4688 - r2_score: 4.4620e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4986 - mean_absolute_error: 0.4689 - r2_score: 2.3770e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4986 - mean_absolute_error: 0.4688 - r2_score: 2.8121e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4983 - mean_absolute_error: 0.4686 - r2_score: 8.6612e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4985 - mean_absolute_error: 0.4687 - r2_score: 4.4757e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4985 - mean_absolute_error: 0.4686 - r2_score: 5.3132e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4982 - mean_absolute_error: 0.4686 - r2_score: 0.0010\n",
      "Processing 19400\n",
      "Processing 19500\n",
      "Processing 19600\n",
      "Processing 19700\n",
      "Processing 19800\n",
      "Processing 19900\n",
      "Processing 20000\n",
      "Processing 20100\n",
      "Processing 20200\n",
      "Processing 20300\n",
      "Check for past dataframe cleanness: (35816, 100) 0\n",
      "Processing 20400\n",
      "Processing 20500\n",
      "Processing 20600\n",
      "Processing 20700\n",
      "Processing 20800\n",
      "Processing 20900\n",
      "Processing 21000\n",
      "Processing 21100\n",
      "Processing 21200\n",
      "Check for past dataframe cleanness: (67760, 100) 0\n",
      "Processing 21300\n",
      "Processing 21400\n",
      "Processing 21500\n",
      "Processing 21600\n",
      "Processing 21700\n",
      "Processing 21800\n",
      "Processing 21900\n",
      "Processing 22000\n",
      "Processing 22100\n",
      "Processing 22200\n",
      "Check for past dataframe cleanness: (105512, 100) 0\n",
      "Processing 22300\n",
      "Processing 22400\n",
      "Processing 22500\n",
      "Processing 22600\n",
      "Processing 22700\n",
      "Processing 22800\n",
      "Processing 22900\n",
      "Processing 23000\n",
      "Processing 23100\n",
      "Processing 23200\n",
      "Check for past dataframe cleanness: (143264, 100) 0\n",
      "Processing 23300\n",
      "Processing 23400\n",
      "Processing 23500\n",
      "Processing 23600\n",
      "Processing 23700\n",
      "Processing 23800\n",
      "Processing 23900\n",
      "Processing 24000\n",
      "Processing 24100\n",
      "Processing 24200\n",
      "Check for past dataframe cleanness: (180048, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5583 - mean_absolute_error: 0.4892 - r2_score: 0.0103\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5582 - mean_absolute_error: 0.4890 - r2_score: 0.0104\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5583 - mean_absolute_error: 0.4891 - r2_score: 0.0103\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5584 - mean_absolute_error: 0.4891 - r2_score: 0.0101\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5583 - mean_absolute_error: 0.4889 - r2_score: 0.0102\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5581 - mean_absolute_error: 0.4890 - r2_score: 0.0107\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5577 - mean_absolute_error: 0.4891 - r2_score: 0.0113\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5576 - mean_absolute_error: 0.4889 - r2_score: 0.0116\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5576 - mean_absolute_error: 0.4890 - r2_score: 0.0114\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5576 - mean_absolute_error: 0.4889 - r2_score: 0.0115\n",
      "Processing 24300\n",
      "Processing 24400\n",
      "Processing 24500\n",
      "Processing 24600\n",
      "Processing 24700\n",
      "Processing 24800\n",
      "Processing 24900\n",
      "Processing 25000\n",
      "Processing 25100\n",
      "Check for past dataframe cleanness: (34848, 100) 0\n",
      "Processing 25200\n",
      "Processing 25300\n",
      "Processing 25400\n",
      "Processing 25500\n",
      "Processing 25600\n",
      "Processing 25700\n",
      "Processing 25800\n",
      "Processing 25900\n",
      "Processing 26000\n",
      "Processing 26100\n",
      "Check for past dataframe cleanness: (72600, 100) 0\n",
      "Processing 26200\n",
      "Processing 26300\n",
      "Processing 26400\n",
      "Processing 26500\n",
      "Processing 26600\n",
      "Processing 26700\n",
      "Processing 26800\n",
      "Processing 26900\n",
      "Processing 27000\n",
      "Processing 27100\n",
      "Check for past dataframe cleanness: (110352, 100) 0\n",
      "Processing 27200\n",
      "Processing 27300\n",
      "Processing 27400\n",
      "Processing 27500\n",
      "Processing 27600\n",
      "Processing 27700\n",
      "Processing 27800\n",
      "Processing 27900\n",
      "Processing 28000\n",
      "Check for past dataframe cleanness: (148104, 100) 0\n",
      "Processing 28100\n",
      "Processing 28200\n",
      "Processing 28300\n",
      "Processing 28400\n",
      "Processing 28500\n",
      "Processing 28600\n",
      "Processing 28700\n",
      "Processing 28800\n",
      "Processing 28900\n",
      "Processing 29000\n",
      "Check for past dataframe cleanness: (185856, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 1.6194 - mean_absolute_error: 0.7633 - r2_score: -9.2590e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6197 - mean_absolute_error: 0.7633 - r2_score: -0.0011\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6189 - mean_absolute_error: 0.7632 - r2_score: -5.9640e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6184 - mean_absolute_error: 0.7632 - r2_score: -2.9087e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6182 - mean_absolute_error: 0.7633 - r2_score: -2.2089e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6182 - mean_absolute_error: 0.7632 - r2_score: -1.9407e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6177 - mean_absolute_error: 0.7633 - r2_score: 1.2594e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6182 - mean_absolute_error: 0.7634 - r2_score: -1.9526e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6177 - mean_absolute_error: 0.7634 - r2_score: 1.3053e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6176 - mean_absolute_error: 0.7634 - r2_score: 2.0713e-04\n",
      "Processing 29100\n",
      "Processing 29200\n",
      "Processing 29300\n",
      "Processing 29400\n",
      "Processing 29500\n",
      "Processing 29600\n",
      "Processing 29700\n",
      "Processing 29800\n",
      "Processing 29900\n",
      "Processing 30000\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 30100\n",
      "Processing 30200\n",
      "Processing 30300\n",
      "Processing 30400\n",
      "Processing 30500\n",
      "Processing 30600\n",
      "Processing 30700\n",
      "Processing 30800\n",
      "Processing 30900\n",
      "Check for past dataframe cleanness: (74536, 100) 0\n",
      "Processing 31000\n",
      "Processing 31100\n",
      "Processing 31200\n",
      "Processing 31300\n",
      "Processing 31400\n",
      "Processing 31500\n",
      "Processing 31600\n",
      "Processing 31700\n",
      "Processing 31800\n",
      "Processing 31900\n",
      "Check for past dataframe cleanness: (112288, 100) 0\n",
      "Processing 32000\n",
      "Processing 32100\n",
      "Processing 32200\n",
      "Processing 32300\n",
      "Processing 32400\n",
      "Processing 32500\n",
      "Processing 32600\n",
      "Processing 32700\n",
      "Processing 32800\n",
      "Processing 32900\n",
      "Check for past dataframe cleanness: (149072, 100) 0\n",
      "Processing 33000\n",
      "Processing 33100\n",
      "Processing 33200\n",
      "Processing 33300\n",
      "Processing 33400\n",
      "Processing 33500\n",
      "Processing 33600\n",
      "Processing 33700\n",
      "Processing 33800\n",
      "Check for past dataframe cleanness: (186824, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4933 - mean_absolute_error: 0.4602 - r2_score: 0.0035\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4932 - mean_absolute_error: 0.4602 - r2_score: 0.0037\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4932 - mean_absolute_error: 0.4600 - r2_score: 0.0037\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4931 - mean_absolute_error: 0.4601 - r2_score: 0.0039\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4933 - mean_absolute_error: 0.4602 - r2_score: 0.0035\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4930 - mean_absolute_error: 0.4601 - r2_score: 0.0041\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4932 - mean_absolute_error: 0.4601 - r2_score: 0.0038\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4935 - mean_absolute_error: 0.4601 - r2_score: 0.0031\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4931 - mean_absolute_error: 0.4601 - r2_score: 0.0038\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4934 - mean_absolute_error: 0.4602 - r2_score: 0.0033\n",
      "Processing 33900\n",
      "Processing 34000\n",
      "Processing 34100\n",
      "Processing 34200\n",
      "Processing 34300\n",
      "Processing 34400\n",
      "Processing 34500\n",
      "Processing 34600\n",
      "Processing 34700\n",
      "Processing 34800\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 34900\n",
      "Processing 35000\n",
      "Processing 35100\n",
      "Processing 35200\n",
      "Processing 35300\n",
      "Processing 35400\n",
      "Processing 35500\n",
      "Processing 35600\n",
      "Processing 35700\n",
      "Processing 35800\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 35900\n",
      "Processing 36000\n",
      "Processing 36100\n",
      "Processing 36200\n",
      "Processing 36300\n",
      "Processing 36400\n",
      "Processing 36500\n",
      "Processing 36600\n",
      "Processing 36700\n",
      "Check for past dataframe cleanness: (113256, 100) 0\n",
      "Processing 36800\n",
      "Processing 36900\n",
      "Processing 37000\n",
      "Processing 37100\n",
      "Processing 37200\n",
      "Processing 37300\n",
      "Processing 37400\n",
      "Processing 37500\n",
      "Processing 37600\n",
      "Processing 37700\n",
      "Check for past dataframe cleanness: (151008, 100) 0\n",
      "Processing 37800\n",
      "Processing 37900\n",
      "Processing 38000\n",
      "Processing 38100\n",
      "Processing 38200\n",
      "Processing 38300\n",
      "Processing 38400\n",
      "Processing 38500\n",
      "Processing 38600\n",
      "Processing 38700\n",
      "Check for past dataframe cleanness: (187792, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5142 - mean_absolute_error: 0.4813 - r2_score: 0.0018\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5144 - mean_absolute_error: 0.4814 - r2_score: 0.0014\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5140 - mean_absolute_error: 0.4813 - r2_score: 0.0022\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5138 - mean_absolute_error: 0.4813 - r2_score: 0.0025\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5138 - mean_absolute_error: 0.4813 - r2_score: 0.0025\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5141 - mean_absolute_error: 0.4812 - r2_score: 0.0019\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5140 - mean_absolute_error: 0.4813 - r2_score: 0.0021\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5143 - mean_absolute_error: 0.4813 - r2_score: 0.0016\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5138 - mean_absolute_error: 0.4812 - r2_score: 0.0026\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5142 - mean_absolute_error: 0.4812 - r2_score: 0.0018\n",
      "Processing 38800\n",
      "Processing 38900\n",
      "Processing 39000\n",
      "Processing 39100\n",
      "Processing 39200\n",
      "Processing 39300\n",
      "Processing 39400\n",
      "Processing 39500\n",
      "Processing 39600\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 39700\n",
      "Processing 39800\n",
      "Processing 39900\n",
      "Processing 40000\n",
      "Processing 40100\n",
      "Processing 40200\n",
      "Processing 40300\n",
      "Processing 40400\n",
      "Processing 40500\n",
      "Processing 40600\n",
      "Check for past dataframe cleanness: (74536, 100) 0\n",
      "Processing 40700\n",
      "Processing 40800\n",
      "Processing 40900\n",
      "Processing 41000\n",
      "Processing 41100\n",
      "Processing 41200\n",
      "Processing 41300\n",
      "Processing 41400\n",
      "Processing 41500\n",
      "Processing 41600\n",
      "Check for past dataframe cleanness: (111320, 100) 0\n",
      "Processing 41700\n",
      "Processing 41800\n",
      "Processing 41900\n",
      "Processing 42000\n",
      "Processing 42100\n",
      "Processing 42200\n",
      "Processing 42300\n",
      "Processing 42400\n",
      "Processing 42500\n",
      "Check for past dataframe cleanness: (149072, 100) 0\n",
      "Processing 42600\n",
      "Processing 42700\n",
      "Processing 42800\n",
      "Processing 42900\n",
      "Processing 43000\n",
      "Processing 43100\n",
      "Processing 43200\n",
      "Processing 43300\n",
      "Processing 43400\n",
      "Processing 43500\n",
      "Check for past dataframe cleanness: (186824, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5122 - mean_absolute_error: 0.4664 - r2_score: 0.0061\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5120 - mean_absolute_error: 0.4661 - r2_score: 0.0067\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5122 - mean_absolute_error: 0.4664 - r2_score: 0.0061\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5120 - mean_absolute_error: 0.4663 - r2_score: 0.0066\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5123 - mean_absolute_error: 0.4662 - r2_score: 0.0061\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5122 - mean_absolute_error: 0.4662 - r2_score: 0.0063\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5122 - mean_absolute_error: 0.4662 - r2_score: 0.0062\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5123 - mean_absolute_error: 0.4663 - r2_score: 0.0061\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5120 - mean_absolute_error: 0.4661 - r2_score: 0.0066\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5120 - mean_absolute_error: 0.4662 - r2_score: 0.0065\n",
      "Processing 43600\n",
      "Processing 43700\n",
      "Processing 43800\n",
      "Processing 43900\n",
      "Processing 44000\n",
      "Processing 44100\n",
      "Processing 44200\n",
      "Processing 44300\n",
      "Processing 44400\n",
      "Processing 44500\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 44600\n",
      "Processing 44700\n",
      "Processing 44800\n",
      "Processing 44900\n",
      "Processing 45000\n",
      "Processing 45100\n",
      "Processing 45200\n",
      "Processing 45300\n",
      "Processing 45400\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 45500\n",
      "Processing 45600\n",
      "Processing 45700\n",
      "Processing 45800\n",
      "Processing 45900\n",
      "Processing 46000\n",
      "Processing 46100\n",
      "Processing 46200\n",
      "Processing 46300\n",
      "Processing 46400\n",
      "Check for past dataframe cleanness: (113256, 100) 0\n",
      "Processing 46500\n",
      "Processing 46600\n",
      "Processing 46700\n",
      "Processing 46800\n",
      "Processing 46900\n",
      "Processing 47000\n",
      "Processing 47100\n",
      "Processing 47200\n",
      "Processing 47300\n",
      "Processing 47400\n",
      "Check for past dataframe cleanness: (151008, 100) 0\n",
      "Processing 47500\n",
      "Processing 47600\n",
      "Processing 47700\n",
      "Processing 47800\n",
      "Processing 47900\n",
      "Processing 48000\n",
      "Processing 48100\n",
      "Processing 48200\n",
      "Processing 48300\n",
      "Processing 48400\n",
      "Check for past dataframe cleanness: (188760, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5321 - mean_absolute_error: 0.4697 - r2_score: 0.0077\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5323 - mean_absolute_error: 0.4696 - r2_score: 0.0074\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5320 - mean_absolute_error: 0.4694 - r2_score: 0.0080\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5322 - mean_absolute_error: 0.4695 - r2_score: 0.0075\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5320 - mean_absolute_error: 0.4696 - r2_score: 0.0079\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5319 - mean_absolute_error: 0.4694 - r2_score: 0.0081\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5318 - mean_absolute_error: 0.4694 - r2_score: 0.0083\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5319 - mean_absolute_error: 0.4695 - r2_score: 0.0081\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.5318 - mean_absolute_error: 0.4695 - r2_score: 0.0082\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.5322 - mean_absolute_error: 0.4696 - r2_score: 0.0076\n",
      "Processing 48500\n",
      "Processing 48600\n",
      "Processing 48700\n",
      "Processing 48800\n",
      "Processing 48900\n",
      "Processing 49000\n",
      "Processing 49100\n",
      "Processing 49200\n",
      "Processing 49300\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 49400\n",
      "Processing 49500\n",
      "Processing 49600\n",
      "Processing 49700\n",
      "Processing 49800\n",
      "Processing 49900\n",
      "Processing 50000\n",
      "Processing 50100\n",
      "Processing 50200\n",
      "Processing 50300\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 50400\n",
      "Processing 50500\n",
      "Processing 50600\n",
      "Processing 50700\n",
      "Processing 50800\n",
      "Processing 50900\n",
      "Processing 51000\n",
      "Processing 51100\n",
      "Processing 51200\n",
      "Processing 51300\n",
      "Check for past dataframe cleanness: (111320, 100) 0\n",
      "Processing 51400\n",
      "Processing 51500\n",
      "Processing 51600\n",
      "Processing 51700\n",
      "Processing 51800\n",
      "Processing 51900\n",
      "Processing 52000\n",
      "Processing 52100\n",
      "Processing 52200\n",
      "Check for past dataframe cleanness: (149072, 100) 0\n",
      "Processing 52300\n",
      "Processing 52400\n",
      "Processing 52500\n",
      "Processing 52600\n",
      "Processing 52700\n",
      "Processing 52800\n",
      "Processing 52900\n",
      "Processing 53000\n",
      "Processing 53100\n",
      "Processing 53200\n",
      "Check for past dataframe cleanness: (185856, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.6228 - mean_absolute_error: 0.5154 - r2_score: 0.0071\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6231 - mean_absolute_error: 0.5153 - r2_score: 0.0066\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.6230 - mean_absolute_error: 0.5154 - r2_score: 0.0067\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6228 - mean_absolute_error: 0.5151 - r2_score: 0.0071\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6231 - mean_absolute_error: 0.5154 - r2_score: 0.0066\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6231 - mean_absolute_error: 0.5154 - r2_score: 0.0066\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6225 - mean_absolute_error: 0.5151 - r2_score: 0.0076\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6226 - mean_absolute_error: 0.5151 - r2_score: 0.0073\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6230 - mean_absolute_error: 0.5151 - r2_score: 0.0067\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6228 - mean_absolute_error: 0.5152 - r2_score: 0.0071\n",
      "Processing 53300\n",
      "Processing 53400\n",
      "Processing 53500\n",
      "Processing 53600\n",
      "Processing 53700\n",
      "Processing 53800\n",
      "Processing 53900\n",
      "Processing 54000\n",
      "Processing 54100\n",
      "Processing 54200\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 54300\n",
      "Processing 54400\n",
      "Processing 54500\n",
      "Processing 54600\n",
      "Processing 54700\n",
      "Processing 54800\n",
      "Processing 54900\n",
      "Processing 55000\n",
      "Processing 55100\n",
      "Check for past dataframe cleanness: (72600, 100) 0\n",
      "Processing 55200\n",
      "Processing 55300\n",
      "Processing 55400\n",
      "Processing 55500\n",
      "Processing 55600\n",
      "Processing 55700\n",
      "Processing 55800\n",
      "Processing 55900\n",
      "Processing 56000\n",
      "Processing 56100\n",
      "Check for past dataframe cleanness: (110352, 100) 0\n",
      "Processing 56200\n",
      "Processing 56300\n",
      "Processing 56400\n",
      "Processing 56500\n",
      "Processing 56600\n",
      "Processing 56700\n",
      "Processing 56800\n",
      "Processing 56900\n",
      "Processing 57000\n",
      "Processing 57100\n",
      "Check for past dataframe cleanness: (147136, 100) 0\n",
      "Processing 57200\n",
      "Processing 57300\n",
      "Processing 57400\n",
      "Processing 57500\n",
      "Processing 57600\n",
      "Processing 57700\n",
      "Processing 57800\n",
      "Processing 57900\n",
      "Processing 58000\n",
      "Check for past dataframe cleanness: (184888, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.6831 - mean_absolute_error: 0.5417 - r2_score: 0.0049\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.6822 - mean_absolute_error: 0.5416 - r2_score: 0.0061\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6827 - mean_absolute_error: 0.5417 - r2_score: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6826 - mean_absolute_error: 0.5417 - r2_score: 0.0055\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6823 - mean_absolute_error: 0.5417 - r2_score: 0.0060\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6832 - mean_absolute_error: 0.5418 - r2_score: 0.0047\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6823 - mean_absolute_error: 0.5416 - r2_score: 0.0059\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6827 - mean_absolute_error: 0.5417 - r2_score: 0.0054\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6824 - mean_absolute_error: 0.5415 - r2_score: 0.0058\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6829 - mean_absolute_error: 0.5416 - r2_score: 0.0052\n",
      "Processing 58100\n",
      "Processing 58200\n",
      "Processing 58300\n",
      "Processing 58400\n",
      "Processing 58500\n",
      "Processing 58600\n",
      "Processing 58700\n",
      "Processing 58800\n",
      "Processing 58900\n",
      "Processing 59000\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 59100\n",
      "Processing 59200\n",
      "Processing 59300\n",
      "Processing 59400\n",
      "Processing 59500\n",
      "Processing 59600\n",
      "Processing 59700\n",
      "Processing 59800\n",
      "Processing 59900\n",
      "Processing 60000\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 60100\n",
      "Processing 60200\n",
      "Processing 60300\n",
      "Processing 60400\n",
      "Processing 60500\n",
      "Processing 60600\n",
      "Processing 60700\n",
      "Processing 60800\n",
      "Processing 60900\n",
      "Check for past dataframe cleanness: (113256, 100) 0\n",
      "Processing 61000\n",
      "Processing 61100\n",
      "Processing 61200\n",
      "Processing 61300\n",
      "Processing 61400\n",
      "Processing 61500\n",
      "Processing 61600\n",
      "Processing 61700\n",
      "Processing 61800\n",
      "Processing 61900\n",
      "Check for past dataframe cleanness: (147136, 100) 0\n",
      "Processing 62000\n",
      "Processing 62100\n",
      "Processing 62200\n",
      "Processing 62300\n",
      "Processing 62400\n",
      "Processing 62500\n",
      "Processing 62600\n",
      "Processing 62700\n",
      "Processing 62800\n",
      "Processing 62900\n",
      "Check for past dataframe cleanness: (183920, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.8225 - mean_absolute_error: 0.5914 - r2_score: 0.0098\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8229 - mean_absolute_error: 0.5915 - r2_score: 0.0092\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8228 - mean_absolute_error: 0.5913 - r2_score: 0.0095\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8223 - mean_absolute_error: 0.5914 - r2_score: 0.0101\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8228 - mean_absolute_error: 0.5914 - r2_score: 0.0094\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8218 - mean_absolute_error: 0.5910 - r2_score: 0.0106\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8218 - mean_absolute_error: 0.5911 - r2_score: 0.0106\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8220 - mean_absolute_error: 0.5912 - r2_score: 0.0104\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8217 - mean_absolute_error: 0.5910 - r2_score: 0.0107\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8224 - mean_absolute_error: 0.5911 - r2_score: 0.0099\n",
      "Processing 63000\n",
      "Processing 63100\n",
      "Processing 63200\n",
      "Processing 63300\n",
      "Processing 63400\n",
      "Processing 63500\n",
      "Processing 63600\n",
      "Processing 63700\n",
      "Processing 63800\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 63900\n",
      "Processing 64000\n",
      "Processing 64100\n",
      "Processing 64200\n",
      "Processing 64300\n",
      "Processing 64400\n",
      "Processing 64500\n",
      "Processing 64600\n",
      "Processing 64700\n",
      "Processing 64800\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 64900\n",
      "Processing 65000\n",
      "Processing 65100\n",
      "Processing 65200\n",
      "Processing 65300\n",
      "Processing 65400\n",
      "Processing 65500\n",
      "Processing 65600\n",
      "Processing 65700\n",
      "Processing 65800\n",
      "Check for past dataframe cleanness: (110352, 100) 0\n",
      "Processing 65900\n",
      "Processing 66000\n",
      "Processing 66100\n",
      "Processing 66200\n",
      "Processing 66300\n",
      "Processing 66400\n",
      "Processing 66500\n",
      "Processing 66600\n",
      "Processing 66700\n",
      "Check for past dataframe cleanness: (148104, 100) 0\n",
      "Processing 66800\n",
      "Processing 66900\n",
      "Processing 67000\n",
      "Processing 67100\n",
      "Processing 67200\n",
      "Processing 67300\n",
      "Processing 67400\n",
      "Processing 67500\n",
      "Processing 67600\n",
      "Processing 67700\n",
      "Check for past dataframe cleanness: (184888, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.8283 - mean_absolute_error: 0.6052 - r2_score: 0.0159\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8283 - mean_absolute_error: 0.6052 - r2_score: 0.0159\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8284 - mean_absolute_error: 0.6053 - r2_score: 0.0157\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8284 - mean_absolute_error: 0.6054 - r2_score: 0.0158\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8283 - mean_absolute_error: 0.6051 - r2_score: 0.0159\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8283 - mean_absolute_error: 0.6053 - r2_score: 0.0158\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8277 - mean_absolute_error: 0.6052 - r2_score: 0.0166\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.8280 - mean_absolute_error: 0.6052 - r2_score: 0.0162\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8281 - mean_absolute_error: 0.6052 - r2_score: 0.0162\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8279 - mean_absolute_error: 0.6051 - r2_score: 0.0164\n",
      "Processing 67800\n",
      "Processing 67900\n",
      "Processing 68000\n",
      "Processing 68100\n",
      "Processing 68200\n",
      "Processing 68300\n",
      "Processing 68400\n",
      "Processing 68500\n",
      "Processing 68600\n",
      "Processing 68700\n",
      "Check for past dataframe cleanness: (34848, 100) 0\n",
      "Processing 68800\n",
      "Processing 68900\n",
      "Processing 69000\n",
      "Processing 69100\n",
      "Processing 69200\n",
      "Processing 69300\n",
      "Processing 69400\n",
      "Processing 69500\n",
      "Processing 69600\n",
      "Check for past dataframe cleanness: (71632, 100) 0\n",
      "Processing 69700\n",
      "Processing 69800\n",
      "Processing 69900\n",
      "Processing 70000\n",
      "Processing 70100\n",
      "Processing 70200\n",
      "Processing 70300\n",
      "Processing 70400\n",
      "Processing 70500\n",
      "Processing 70600\n",
      "Check for past dataframe cleanness: (107448, 100) 0\n",
      "Processing 70700\n",
      "Processing 70800\n",
      "Processing 70900\n",
      "Processing 71000\n",
      "Processing 71100\n",
      "Processing 71200\n",
      "Processing 71300\n",
      "Processing 71400\n",
      "Processing 71500\n",
      "Processing 71600\n",
      "Check for past dataframe cleanness: (143264, 100) 0\n",
      "Processing 71700\n",
      "Processing 71800\n",
      "Processing 71900\n",
      "Processing 72000\n",
      "Processing 72100\n",
      "Processing 72200\n",
      "Processing 72300\n",
      "Processing 72400\n",
      "Processing 72500\n",
      "Processing 72600\n",
      "Check for past dataframe cleanness: (181016, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 1.0937 - mean_absolute_error: 0.6943 - r2_score: 0.0040\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0937 - mean_absolute_error: 0.6944 - r2_score: 0.0039\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0924 - mean_absolute_error: 0.6942 - r2_score: 0.0051\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0927 - mean_absolute_error: 0.6944 - r2_score: 0.0049\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0928 - mean_absolute_error: 0.6943 - r2_score: 0.0047\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0923 - mean_absolute_error: 0.6942 - r2_score: 0.0052\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0927 - mean_absolute_error: 0.6942 - r2_score: 0.0048\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0929 - mean_absolute_error: 0.6942 - r2_score: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0924 - mean_absolute_error: 0.6940 - r2_score: 0.0051\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0928 - mean_absolute_error: 0.6942 - r2_score: 0.0048\n",
      "Processing 72700\n",
      "Processing 72800\n",
      "Processing 72900\n",
      "Processing 73000\n",
      "Processing 73100\n",
      "Processing 73200\n",
      "Processing 73300\n",
      "Processing 73400\n",
      "Processing 73500\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 73600\n",
      "Processing 73700\n",
      "Processing 73800\n",
      "Processing 73900\n",
      "Processing 74000\n",
      "Processing 74100\n",
      "Processing 74200\n",
      "Processing 74300\n",
      "Processing 74400\n",
      "Processing 74500\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 74600\n",
      "Processing 74700\n",
      "Processing 74800\n",
      "Processing 74900\n",
      "Processing 75000\n",
      "Processing 75100\n",
      "Processing 75200\n",
      "Processing 75300\n",
      "Processing 75400\n",
      "Processing 75500\n",
      "Check for past dataframe cleanness: (113256, 100) 0\n",
      "Processing 75600\n",
      "Processing 75700\n",
      "Processing 75800\n",
      "Processing 75900\n",
      "Processing 76000\n",
      "Processing 76100\n",
      "Processing 76200\n",
      "Processing 76300\n",
      "Processing 76400\n",
      "Check for past dataframe cleanness: (151008, 100) 0\n",
      "Processing 76500\n",
      "Processing 76600\n",
      "Processing 76700\n",
      "Processing 76800\n",
      "Processing 76900\n",
      "Processing 77000\n",
      "Processing 77100\n",
      "Processing 77200\n",
      "Processing 77300\n",
      "Processing 77400\n",
      "Check for past dataframe cleanness: (188760, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.8499 - mean_absolute_error: 0.6085 - r2_score: 0.0061\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8499 - mean_absolute_error: 0.6085 - r2_score: 0.0061\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8499 - mean_absolute_error: 0.6086 - r2_score: 0.0061\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8497 - mean_absolute_error: 0.6085 - r2_score: 0.0063\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8498 - mean_absolute_error: 0.6084 - r2_score: 0.0062\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8497 - mean_absolute_error: 0.6085 - r2_score: 0.0063\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8495 - mean_absolute_error: 0.6085 - r2_score: 0.0066\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8496 - mean_absolute_error: 0.6084 - r2_score: 0.0064\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8496 - mean_absolute_error: 0.6085 - r2_score: 0.0065\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8499 - mean_absolute_error: 0.6084 - r2_score: 0.0061\n",
      "Processing 77500\n",
      "Processing 77600\n",
      "Processing 77700\n",
      "Processing 77800\n",
      "Processing 77900\n",
      "Processing 78000\n",
      "Processing 78100\n",
      "Processing 78200\n",
      "Processing 78300\n",
      "Processing 78400\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 78500\n",
      "Processing 78600\n",
      "Processing 78700\n",
      "Processing 78800\n",
      "Processing 78900\n",
      "Processing 79000\n",
      "Processing 79100\n",
      "Processing 79200\n",
      "Processing 79300\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 79400\n",
      "Processing 79500\n",
      "Processing 79600\n",
      "Processing 79700\n",
      "Processing 79800\n",
      "Processing 79900\n",
      "Processing 80000\n",
      "Processing 80100\n",
      "Processing 80200\n",
      "Processing 80300\n",
      "Check for past dataframe cleanness: (112288, 100) 0\n",
      "Processing 80400\n",
      "Processing 80500\n",
      "Processing 80600\n",
      "Processing 80700\n",
      "Processing 80800\n",
      "Processing 80900\n",
      "Processing 81000\n",
      "Processing 81100\n",
      "Processing 81200\n",
      "Processing 81300\n",
      "Check for past dataframe cleanness: (150040, 100) 0\n",
      "Processing 81400\n",
      "Processing 81500\n",
      "Processing 81600\n",
      "Processing 81700\n",
      "Processing 81800\n",
      "Processing 81900\n",
      "Processing 82000\n",
      "Processing 82100\n",
      "Processing 82200\n",
      "Check for past dataframe cleanness: (187792, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.7457 - mean_absolute_error: 0.5848 - r2_score: 0.0050\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7455 - mean_absolute_error: 0.5845 - r2_score: 0.0054\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7457 - mean_absolute_error: 0.5847 - r2_score: 0.0051\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7456 - mean_absolute_error: 0.5847 - r2_score: 0.0052\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7452 - mean_absolute_error: 0.5846 - r2_score: 0.0058\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7454 - mean_absolute_error: 0.5845 - r2_score: 0.0055\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7455 - mean_absolute_error: 0.5846 - r2_score: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7452 - mean_absolute_error: 0.5845 - r2_score: 0.0057\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7453 - mean_absolute_error: 0.5846 - r2_score: 0.0056\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7447 - mean_absolute_error: 0.5845 - r2_score: 0.0064\n",
      "Processing 82300\n",
      "Processing 82400\n",
      "Processing 82500\n",
      "Processing 82600\n",
      "Processing 82700\n",
      "Processing 82800\n",
      "Processing 82900\n",
      "Processing 83000\n",
      "Processing 83100\n",
      "Processing 83200\n",
      "Check for past dataframe cleanness: (36784, 100) 0\n",
      "Processing 83300\n",
      "Processing 83400\n",
      "Processing 83500\n",
      "Processing 83600\n",
      "Processing 83700\n",
      "Processing 83800\n",
      "Processing 83900\n",
      "Processing 84000\n",
      "Processing 84100\n",
      "Processing 84200\n",
      "Check for past dataframe cleanness: (74536, 100) 0\n",
      "Processing 84300\n",
      "Processing 84400\n",
      "Processing 84500\n",
      "Processing 84600\n",
      "Processing 84700\n",
      "Processing 84800\n",
      "Processing 84900\n",
      "Processing 85000\n",
      "Processing 85100\n",
      "Check for past dataframe cleanness: (112288, 100) 0\n",
      "Processing 85200\n",
      "Processing 85300\n",
      "Processing 85400\n",
      "Processing 85500\n",
      "Processing 85600\n",
      "Processing 85700\n",
      "Processing 85800\n",
      "Processing 85900\n",
      "Processing 86000\n",
      "Processing 86100\n",
      "Check for past dataframe cleanness: (148104, 100) 0\n",
      "Processing 86200\n",
      "Processing 86300\n",
      "Processing 86400\n",
      "Processing 86500\n",
      "Processing 86600\n",
      "Processing 86700\n",
      "Processing 86800\n",
      "Processing 86900\n",
      "Processing 87000\n",
      "Processing 87100\n",
      "Check for past dataframe cleanness: (184888, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.6739 - mean_absolute_error: 0.5534 - r2_score: 0.0020\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6740 - mean_absolute_error: 0.5535 - r2_score: 0.0018\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6744 - mean_absolute_error: 0.5535 - r2_score: 0.0012\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6739 - mean_absolute_error: 0.5534 - r2_score: 0.0020\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6739 - mean_absolute_error: 0.5534 - r2_score: 0.0019\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6734 - mean_absolute_error: 0.5533 - r2_score: 0.0027\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6740 - mean_absolute_error: 0.5534 - r2_score: 0.0019\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6739 - mean_absolute_error: 0.5533 - r2_score: 0.0020\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6738 - mean_absolute_error: 0.5533 - r2_score: 0.0022\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6742 - mean_absolute_error: 0.5535 - r2_score: 0.0015\n",
      "Processing 87200\n",
      "Processing 87300\n",
      "Processing 87400\n",
      "Processing 87500\n",
      "Processing 87600\n",
      "Processing 87700\n",
      "Processing 87800\n",
      "Processing 87900\n",
      "Processing 88000\n",
      "Check for past dataframe cleanness: (36784, 100) 0\n",
      "Processing 88100\n",
      "Processing 88200\n",
      "Processing 88300\n",
      "Processing 88400\n",
      "Processing 88500\n",
      "Processing 88600\n",
      "Processing 88700\n",
      "Processing 88800\n",
      "Processing 88900\n",
      "Processing 89000\n",
      "Check for past dataframe cleanness: (73568, 100) 0\n",
      "Processing 89100\n",
      "Processing 89200\n",
      "Processing 89300\n",
      "Processing 89400\n",
      "Processing 89500\n",
      "Processing 89600\n",
      "Processing 89700\n",
      "Processing 89800\n",
      "Processing 89900\n",
      "Processing 90000\n",
      "Check for past dataframe cleanness: (110352, 100) 0\n",
      "Processing 90100\n",
      "Processing 90200\n",
      "Processing 90300\n",
      "Processing 90400\n",
      "Processing 90500\n",
      "Processing 90600\n",
      "Processing 90700\n",
      "Processing 90800\n",
      "Processing 90900\n",
      "Check for past dataframe cleanness: (148104, 100) 0\n",
      "Processing 91000\n",
      "Processing 91100\n",
      "Processing 91200\n",
      "Processing 91300\n",
      "Processing 91400\n",
      "Processing 91500\n",
      "Processing 91600\n",
      "Processing 91700\n",
      "Processing 91800\n",
      "Processing 91900\n",
      "Check for past dataframe cleanness: (185856, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.7273 - mean_absolute_error: 0.5638 - r2_score: 0.0033\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7274 - mean_absolute_error: 0.5637 - r2_score: 0.0032\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7268 - mean_absolute_error: 0.5635 - r2_score: 0.0040\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7274 - mean_absolute_error: 0.5637 - r2_score: 0.0032\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7274 - mean_absolute_error: 0.5637 - r2_score: 0.0032\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7275 - mean_absolute_error: 0.5637 - r2_score: 0.0031\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7276 - mean_absolute_error: 0.5637 - r2_score: 0.0030\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7273 - mean_absolute_error: 0.5637 - r2_score: 0.0034\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7274 - mean_absolute_error: 0.5637 - r2_score: 0.0033\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7276 - mean_absolute_error: 0.5637 - r2_score: 0.0030\n",
      "Processing 92000\n",
      "Processing 92100\n",
      "Processing 92200\n",
      "Processing 92300\n",
      "Processing 92400\n",
      "Processing 92500\n",
      "Processing 92600\n",
      "Processing 92700\n",
      "Processing 92800\n",
      "Processing 92900\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 93000\n",
      "Processing 93100\n",
      "Processing 93200\n",
      "Processing 93300\n",
      "Processing 93400\n",
      "Processing 93500\n",
      "Processing 93600\n",
      "Processing 93700\n",
      "Processing 93800\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 93900\n",
      "Processing 94000\n",
      "Processing 94100\n",
      "Processing 94200\n",
      "Processing 94300\n",
      "Processing 94400\n",
      "Processing 94500\n",
      "Processing 94600\n",
      "Processing 94700\n",
      "Processing 94800\n",
      "Check for past dataframe cleanness: (113256, 100) 0\n",
      "Processing 94900\n",
      "Processing 95000\n",
      "Processing 95100\n",
      "Processing 95200\n",
      "Processing 95300\n",
      "Processing 95400\n",
      "Processing 95500\n",
      "Processing 95600\n",
      "Processing 95700\n",
      "Processing 95800\n",
      "Check for past dataframe cleanness: (150040, 100) 0\n",
      "Processing 95900\n",
      "Processing 96000\n",
      "Processing 96100\n",
      "Processing 96200\n",
      "Processing 96300\n",
      "Processing 96400\n",
      "Processing 96500\n",
      "Processing 96600\n",
      "Processing 96700\n",
      "Processing 96800\n",
      "Check for past dataframe cleanness: (187792, 100) 0\n",
      "training new model\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.7197 - mean_absolute_error: 0.5604 - r2_score: 0.0064\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7197 - mean_absolute_error: 0.5603 - r2_score: 0.0064\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7201 - mean_absolute_error: 0.5605 - r2_score: 0.0059\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7202 - mean_absolute_error: 0.5603 - r2_score: 0.0058\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.7193 - mean_absolute_error: 0.5602 - r2_score: 0.0070\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7199 - mean_absolute_error: 0.5604 - r2_score: 0.0061\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7198 - mean_absolute_error: 0.5602 - r2_score: 0.0063\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7197 - mean_absolute_error: 0.5603 - r2_score: 0.0064\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7196 - mean_absolute_error: 0.5604 - r2_score: 0.0066\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.7197 - mean_absolute_error: 0.5604 - r2_score: 0.0064\n",
      "Processing 96900\n",
      "Processing 97000\n",
      "Processing 97100\n",
      "Processing 97200\n",
      "Processing 97300\n",
      "Processing 97400\n",
      "Processing 97500\n",
      "Processing 97600\n",
      "Processing 97700\n",
      "Check for past dataframe cleanness: (37752, 100) 0\n",
      "Processing 97800\n",
      "Processing 97900\n",
      "Processing 98000\n",
      "Processing 98100\n",
      "Processing 98200\n",
      "Processing 98300\n",
      "Processing 98400\n",
      "Processing 98500\n",
      "Processing 98600\n",
      "Processing 98700\n",
      "Check for past dataframe cleanness: (75504, 100) 0\n",
      "Processing 98800\n",
      "Processing 98900\n",
      "Processing 99000\n",
      "Processing 99100\n",
      "Processing 99200\n",
      "Processing 99300\n",
      "Processing 99400\n",
      "Processing 99500\n",
      "Processing 99600\n",
      "Processing 99700\n",
      "Check for past dataframe cleanness: (113256, 100) 0\n",
      "Processing 99800\n",
      "Processing 99900\n",
      "Processing 100000\n"
     ]
    }
   ],
   "source": [
    "lag_send_format = \"(date_id)|(time_id)|(symbol_id)|(responder_\\d)\"\n",
    "num_samples = 100000\n",
    "cur_ind = 0\n",
    "\n",
    "for (date_id, time_id), df in by_days:\n",
    "    cur_ind += 1\n",
    "    if cur_ind > num_samples:\n",
    "        break\n",
    "    if cur_ind % 100 == 0:\n",
    "        print(f\"Processing {cur_ind}\")\n",
    "    lag_send = None\n",
    "    if date_id != last_date:\n",
    "        lag_send = last_lag\n",
    "    else:\n",
    "        lag_send = None\n",
    "\n",
    "    df = df.with_columns(pl.Series(list(range(df.shape[0]))).alias(\"row_id\"))\n",
    "    result = predict(df, lag_send)\n",
    "    \n",
    "    predictions = pl.concat([predictions, result[['responder_6']]])\n",
    "    answers = pl.concat([answers, df[['responder_6']]])\n",
    "    \n",
    "    responders = df[[i for i in df.columns if re.fullmatch(lag_send_format, i)]]\n",
    "\n",
    "    if date_id != last_date:\n",
    "        last_date = date_id\n",
    "        last_lag = responders\n",
    "    else:\n",
    "        if last_lag is None:\n",
    "            last_lag = responders\n",
    "        else:\n",
    "            last_lag = pl.concat([last_lag, responders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b182d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T02:24:41.525010Z",
     "iopub.status.busy": "2024-12-31T02:24:41.523715Z",
     "iopub.status.idle": "2024-12-31T02:24:41.916646Z",
     "shell.execute_reply": "2024-12-31T02:24:41.915467Z"
    },
    "papermill": {
     "duration": 1.896746,
     "end_time": "2024-12-31T02:24:41.918817",
     "exception": false,
     "start_time": "2024-12-31T02:24:40.022071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.008329034>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = tf.metrics.R2Score()\n",
    "metric.update_state(np.asarray(answers['responder_6']).reshape((-1, 1)), np.asarray(predictions['responder_6']).reshape((-1, 1)))\n",
    "metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0b6f0b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T02:24:44.689945Z",
     "iopub.status.busy": "2024-12-31T02:24:44.688712Z",
     "iopub.status.idle": "2024-12-31T02:24:44.715199Z",
     "shell.execute_reply": "2024-12-31T02:24:44.713925Z"
    },
    "papermill": {
     "duration": 1.455275,
     "end_time": "2024-12-31T02:24:44.717462",
     "exception": false,
     "start_time": "2024-12-31T02:24:43.262187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.360012054443359\n",
      "5.5210065841674805\n",
      "5.943350315093994\n",
      "5.845920562744141\n",
      "6.06838321685791\n",
      "5.419388294219971\n",
      "7.608674049377441\n",
      "7.8821516036987305\n",
      "7.446694374084473\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((storage.past_df[f'responder_{i}'] - test_df[f'responder_{i}'][:storage.past_df.shape[0]]).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7c69abc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T02:24:47.606563Z",
     "iopub.status.busy": "2024-12-31T02:24:47.606150Z",
     "iopub.status.idle": "2024-12-31T02:24:47.649996Z",
     "shell.execute_reply": "2024-12-31T02:24:47.648913Z"
    },
    "papermill": {
     "duration": 1.499229,
     "end_time": "2024-12-31T02:24:47.652351",
     "exception": false,
     "start_time": "2024-12-31T02:24:46.153122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.071231  ],\n",
       "       [ 1.9790423 ],\n",
       "       [-0.5062598 ],\n",
       "       ...,\n",
       "       [-0.92973065],\n",
       "       [-0.7898972 ],\n",
       "       [ 0.21184593]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(answers['responder_6']).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c876ebab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T02:24:50.487009Z",
     "iopub.status.busy": "2024-12-31T02:24:50.486520Z",
     "iopub.status.idle": "2024-12-31T02:24:50.523834Z",
     "shell.execute_reply": "2024-12-31T02:24:50.522494Z"
    },
    "papermill": {
     "duration": 1.451333,
     "end_time": "2024-12-31T02:24:50.526833",
     "exception": false,
     "start_time": "2024-12-31T02:24:49.075500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31701842],\n",
       "       [0.33453202],\n",
       "       [0.26945645],\n",
       "       ...,\n",
       "       [0.04558765],\n",
       "       [0.02127514],\n",
       "       [0.02893108]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(predictions['responder_6']).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93147a1",
   "metadata": {
    "papermill": {
     "duration": 1.347386,
     "end_time": "2024-12-31T02:24:53.370187",
     "exception": false,
     "start_time": "2024-12-31T02:24:52.022801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "sourceId": 214656673,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34482.11568,
   "end_time": "2024-12-31T02:24:59.126218",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-30T16:50:17.010538",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
