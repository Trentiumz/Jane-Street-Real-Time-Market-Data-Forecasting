{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47372c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:56:27.352996Z",
     "iopub.status.busy": "2024-12-20T13:56:27.352475Z",
     "iopub.status.idle": "2024-12-20T13:56:45.228292Z",
     "shell.execute_reply": "2024-12-20T13:56:45.226807Z"
    },
    "papermill": {
     "duration": 17.885696,
     "end_time": "2024-12-20T13:56:45.231260",
     "exception": false,
     "start_time": "2024-12-20T13:56:27.345564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import polars as pl # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f1cc8",
   "metadata": {
    "papermill": {
     "duration": 0.004203,
     "end_time": "2024-12-20T13:56:45.240703",
     "exception": false,
     "start_time": "2024-12-20T13:56:45.236500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Read Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb67316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:56:45.253082Z",
     "iopub.status.busy": "2024-12-20T13:56:45.252149Z",
     "iopub.status.idle": "2024-12-20T13:56:45.260852Z",
     "shell.execute_reply": "2024-12-20T13:56:45.259664Z"
    },
    "papermill": {
     "duration": 0.018117,
     "end_time": "2024-12-20T13:56:45.263294",
     "exception": false,
     "start_time": "2024-12-20T13:56:45.245177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = Path(\"/kaggle/input/jane-street-real-time-market-data-forecasting/\")\n",
    "train_path = base_path / Path(\"train.parquet\")\n",
    "train_read_paths = [train_path / Path(f\"partition_id={i}/part-0.parquet\") for i in [0, 1, 2, 3, 4, 5, 6, 7]]\n",
    "val_read_paths = [train_path / Path(f\"partition_id={i}/part-0.parquet\") for i in [8]]\n",
    "test_read_paths = [train_path / Path(f\"partition_id={i}/part-0.parquet\") for i in [9]]\n",
    "\n",
    "load_means_from_file = False\n",
    "means_path = \"/kaggle/working/means.csv\"\n",
    "load_stds_from_file = False\n",
    "stds_path = \"/kaggle/working/stds.csv\"\n",
    "target = \"responder_6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d1c2fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:56:45.277261Z",
     "iopub.status.busy": "2024-12-20T13:56:45.276838Z",
     "iopub.status.idle": "2024-12-20T13:56:45.285164Z",
     "shell.execute_reply": "2024-12-20T13:56:45.284029Z"
    },
    "papermill": {
     "duration": 0.01887,
     "end_time": "2024-12-20T13:56:45.287537",
     "exception": false,
     "start_time": "2024-12-20T13:56:45.268667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    input_format = {\n",
    "        \"date_id\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"time_id\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"symbol_id\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"weight\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        \"features\": tf.TensorSpec(shape=(None, 79), dtype=tf.float32),\n",
    "        \"responders\": tf.TensorSpec(shape=(None, 9), dtype=tf.float32),\n",
    "        \"target\": tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    }\n",
    "    train_batch_size = 32768\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fba9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:56:45.299347Z",
     "iopub.status.busy": "2024-12-20T13:56:45.298895Z",
     "iopub.status.idle": "2024-12-20T13:56:45.481232Z",
     "shell.execute_reply": "2024-12-20T13:56:45.480095Z"
    },
    "papermill": {
     "duration": 0.19077,
     "end_time": "2024-12-20T13:56:45.483826",
     "exception": false,
     "start_time": "2024-12-20T13:56:45.293056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_features(chunk):\n",
    "    return chunk[[i for i in chunk.columns if i.startswith(\"feature_\")]]\n",
    "\n",
    "def from_files(paths):\n",
    "    def to_ret():\n",
    "        for filepath in paths:\n",
    "            chunk = pl.read_parquet(filepath)\n",
    "            yield {\n",
    "                \"date_id\": chunk[\"date_id\"],\n",
    "                \"time_id\": chunk[\"time_id\"],\n",
    "                \"symbol_id\": chunk[\"symbol_id\"],\n",
    "                \"weight\": chunk[\"weight\"],\n",
    "                \"features\": chunk_features(chunk),\n",
    "                \"responders\": chunk[[i for i in chunk.columns if i.startswith(\"responder_\")]],\n",
    "                \"target\": chunk[target]\n",
    "            }\n",
    "    return to_ret\n",
    "\n",
    "train_raw = tf.data.Dataset.from_generator(\n",
    "    from_files(train_read_paths),\n",
    "    output_signature=config.input_format\n",
    ").prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "val_raw = tf.data.Dataset.from_generator(\n",
    "    from_files(val_read_paths),\n",
    "    output_signature=config.input_format\n",
    ").cache()\n",
    "\n",
    "test_raw = tf.data.Dataset.from_generator(\n",
    "    from_files(test_read_paths),\n",
    "    output_signature=config.input_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2222d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:56:45.495023Z",
     "iopub.status.busy": "2024-12-20T13:56:45.494587Z",
     "iopub.status.idle": "2024-12-20T13:56:45.504562Z",
     "shell.execute_reply": "2024-12-20T13:56:45.503053Z"
    },
    "papermill": {
     "duration": 0.019609,
     "end_time": "2024-12-20T13:56:45.507992",
     "exception": false,
     "start_time": "2024-12-20T13:56:45.488383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_id': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'time_id': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'symbol_id': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'weight': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " 'features': TensorSpec(shape=(None, 79), dtype=tf.float32, name=None),\n",
       " 'responders': TensorSpec(shape=(None, 9), dtype=tf.float32, name=None),\n",
       " 'target': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a31167",
   "metadata": {
    "papermill": {
     "duration": 0.004445,
     "end_time": "2024-12-20T13:56:45.517288",
     "exception": false,
     "start_time": "2024-12-20T13:56:45.512843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb84d4de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:56:45.528358Z",
     "iopub.status.busy": "2024-12-20T13:56:45.527965Z",
     "iopub.status.idle": "2024-12-20T14:00:24.088943Z",
     "shell.execute_reply": "2024-12-20T14:00:24.087778Z"
    },
    "papermill": {
     "duration": 218.569482,
     "end_time": "2024-12-20T14:00:24.091705",
     "exception": false,
     "start_time": "2024-12-20T13:56:45.522223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean(dataset):\n",
    "    batched_ds = dataset.batch(10000)\n",
    "    def step(acc, value):\n",
    "        num_non_nan = tf.reduce_sum(tf.cast(tf.math.is_nan(value['features']) == False, tf.float32), axis=0)\n",
    "        sum_non_nan = tf.reduce_sum(tf.where(tf.math.is_nan(value['features']), tf.zeros_like(value['features']), value['features']), axis=0)\n",
    "        return (acc[0] + sum_non_nan, acc[1] + num_non_nan)\n",
    "    \n",
    "    sum_, rows = batched_ds.reduce((tf.zeros(shape=(79,)), tf.constant(0.0)), step)\n",
    "    return sum_ / tf.maximum(rows, tf.ones_like(rows))\n",
    "\n",
    "if load_means_from_file:\n",
    "    means = np.asarray(pl.read_csv(means_path)).astype('float32').reshape((-1,))\n",
    "else:\n",
    "    means = get_mean(train_raw.unbatch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1419d6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:00:24.103529Z",
     "iopub.status.busy": "2024-12-20T14:00:24.103120Z",
     "iopub.status.idle": "2024-12-20T14:00:24.176871Z",
     "shell.execute_reply": "2024-12-20T14:00:24.175786Z"
    },
    "papermill": {
     "duration": 0.082397,
     "end_time": "2024-12-20T14:00:24.179435",
     "exception": false,
     "start_time": "2024-12-20T14:00:24.097038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data(features):\n",
    "    return tf.where(\n",
    "        tf.logical_or(tf.math.is_nan(features), tf.math.is_inf(features)), \n",
    "        means, \n",
    "        features)\n",
    "\n",
    "train_vals = train_raw.map(lambda i: (\n",
    "                        clean_data(i['features']),\n",
    "                        i['target']\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c96af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:00:24.191207Z",
     "iopub.status.busy": "2024-12-20T14:00:24.190064Z",
     "iopub.status.idle": "2024-12-20T14:01:15.682874Z",
     "shell.execute_reply": "2024-12-20T14:01:15.681895Z"
    },
    "papermill": {
     "duration": 51.501221,
     "end_time": "2024-12-20T14:01:15.685304",
     "exception": false,
     "start_time": "2024-12-20T14:00:24.184083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_std(dataset):\n",
    "    batched_ds = dataset.batch(10000)\n",
    "    def step(acc, val):\n",
    "        return (acc[0] + tf.math.reduce_std(val[0], axis=0), acc[1] + 1)\n",
    "    sum_, samples = batched_ds.reduce((tf.zeros(shape=(79,)), tf.constant(0.0)), step)\n",
    "    return sum_ / samples\n",
    "\n",
    "if load_stds_from_file:\n",
    "    stds = np.asarray(pl.read_csv(stds_path)).astype('float32').reshape((-1,))\n",
    "else:\n",
    "    stds = get_std(train_vals.unbatch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b04a074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:01:15.696414Z",
     "iopub.status.busy": "2024-12-20T14:01:15.696032Z",
     "iopub.status.idle": "2024-12-20T14:01:15.982736Z",
     "shell.execute_reply": "2024-12-20T14:01:15.981639Z"
    },
    "papermill": {
     "duration": 0.294859,
     "end_time": "2024-12-20T14:01:15.985059",
     "exception": false,
     "start_time": "2024-12-20T14:01:15.690200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_data(features):\n",
    "    return (features - means) / tf.math.maximum(1.0, stds)\n",
    "\n",
    "train_ds = train_vals.map(lambda feat, tar: (normalize_data(feat), tar)).unbatch().shuffle(10000).batch(config.train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e6c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T04:06:27.478694Z",
     "iopub.status.busy": "2024-12-18T04:06:27.477500Z",
     "iopub.status.idle": "2024-12-18T04:06:27.485848Z",
     "shell.execute_reply": "2024-12-18T04:06:27.484622Z",
     "shell.execute_reply.started": "2024-12-18T04:06:27.478647Z"
    },
    "papermill": {
     "duration": 0.005655,
     "end_time": "2024-12-20T14:01:15.995420",
     "exception": false,
     "start_time": "2024-12-20T14:01:15.989765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3094cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:01:16.006728Z",
     "iopub.status.busy": "2024-12-20T14:01:16.005788Z",
     "iopub.status.idle": "2024-12-20T14:01:16.073905Z",
     "shell.execute_reply": "2024-12-20T14:01:16.072841Z"
    },
    "papermill": {
     "duration": 0.076293,
     "end_time": "2024-12-20T14:01:16.076381",
     "exception": false,
     "start_time": "2024-12-20T14:01:16.000088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = keras.Input(shape=(79,))\n",
    "x = layers.Dense(units=40, activation=\"relu\")(inp)\n",
    "x = layers.Dense(units=30, activation=\"relu\")(x)\n",
    "x = layers.Dense(units=20, activation=\"relu\")(x)\n",
    "x = layers.Dense(units=10, activation=\"relu\")(x)\n",
    "x = layers.Dense(units=1)(x)\n",
    "model = keras.Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d07d660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:01:16.087127Z",
     "iopub.status.busy": "2024-12-20T14:01:16.086731Z",
     "iopub.status.idle": "2024-12-20T14:01:16.107621Z",
     "shell.execute_reply": "2024-12-20T14:01:16.106477Z"
    },
    "papermill": {
     "duration": 0.029179,
     "end_time": "2024-12-20T14:01:16.110214",
     "exception": false,
     "start_time": "2024-12-20T14:01:16.081035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def r2_loss(y_true, y_pred):\n",
    "    return tf.math.reduce_sum((y_true - y_pred) ** 2) / tf.math.reduce_sum(y_true ** 2)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=r2_loss, metrics=[keras.metrics.MeanAbsoluteError(), keras.metrics.R2Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f21f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:01:16.122767Z",
     "iopub.status.busy": "2024-12-20T14:01:16.122344Z",
     "iopub.status.idle": "2024-12-20T14:09:05.492742Z",
     "shell.execute_reply": "2024-12-20T14:09:05.491714Z"
    },
    "papermill": {
     "duration": 469.38009,
     "end_time": "2024-12-20T14:09:05.495313",
     "exception": false,
     "start_time": "2024-12-20T14:01:16.115223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 143ms/step - loss: 1.0046 - mean_absolute_error: 0.6009 - r2_score: -0.0035\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 140ms/step - loss: 0.9866 - mean_absolute_error: 0.5951 - r2_score: 0.0132\n",
      "Epoch 3/3\n",
      "\u001b[1m1060/1060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 142ms/step - loss: 0.9849 - mean_absolute_error: 0.5946 - r2_score: 0.0149\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d030983",
   "metadata": {
    "papermill": {
     "duration": 0.183632,
     "end_time": "2024-12-20T14:09:05.864289",
     "exception": false,
     "start_time": "2024-12-20T14:09:05.680657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04a9e3c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:09:06.233734Z",
     "iopub.status.busy": "2024-12-20T14:09:06.233289Z",
     "iopub.status.idle": "2024-12-20T14:09:06.281124Z",
     "shell.execute_reply": "2024-12-20T14:09:06.279858Z"
    },
    "papermill": {
     "duration": 0.235321,
     "end_time": "2024-12-20T14:09:06.283646",
     "exception": false,
     "start_time": "2024-12-20T14:09:06.048325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.DataFrame({'means': np.asarray(means)}).write_csv('means.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05b1e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:09:06.712480Z",
     "iopub.status.busy": "2024-12-20T14:09:06.712075Z",
     "iopub.status.idle": "2024-12-20T14:09:06.795260Z",
     "shell.execute_reply": "2024-12-20T14:09:06.794193Z"
    },
    "papermill": {
     "duration": 0.330216,
     "end_time": "2024-12-20T14:09:06.797632",
     "exception": false,
     "start_time": "2024-12-20T14:09:06.467416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('fitted.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19fae947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:09:07.158007Z",
     "iopub.status.busy": "2024-12-20T14:09:07.157542Z",
     "iopub.status.idle": "2024-12-20T14:09:07.162896Z",
     "shell.execute_reply": "2024-12-20T14:09:07.162137Z"
    },
    "papermill": {
     "duration": 0.18791,
     "end_time": "2024-12-20T14:09:07.164894",
     "exception": false,
     "start_time": "2024-12-20T14:09:06.976984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.DataFrame({'stds': np.asarray(stds)}).write_csv('stds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7a947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T21:16:33.404263Z",
     "iopub.status.busy": "2024-12-19T21:16:33.403835Z",
     "iopub.status.idle": "2024-12-19T21:16:41.038672Z",
     "shell.execute_reply": "2024-12-19T21:16:41.037480Z",
     "shell.execute_reply.started": "2024-12-19T21:16:33.404225Z"
    },
    "papermill": {
     "duration": 0.178683,
     "end_time": "2024-12-20T14:09:07.523778",
     "exception": false,
     "start_time": "2024-12-20T14:09:07.345095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57352f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:09:07.886338Z",
     "iopub.status.busy": "2024-12-20T14:09:07.885939Z",
     "iopub.status.idle": "2024-12-20T14:09:07.933830Z",
     "shell.execute_reply": "2024-12-20T14:09:07.932720Z"
    },
    "papermill": {
     "duration": 0.231601,
     "end_time": "2024-12-20T14:09:07.936331",
     "exception": false,
     "start_time": "2024-12-20T14:09:07.704730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = test_raw.map(lambda i: (\n",
    "    normalize_data(clean_data(i['features'])),\n",
    "    i['target']\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 767.334559,
   "end_time": "2024-12-20T14:09:11.036014",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-20T13:56:23.701455",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
